# Backend: Adaptive RAG with FastAPI

This backend service implements an Adaptive Retrieval-Augmented Generation (RAG) system using **LangGraph** and exposes it as a REST API with **FastAPI**.

## Overview

The core of this backend is an Adaptive RAG workflow that dynamically decides whether to retrieve information from a vector store or perform a web search based on the user's query. It also includes a grading step to evaluate the relevance of retrieved documents before generating a final answer.

## Features

-   **Dynamic Routing**: Automatically routes questions to either a vector store or a web search based on the query's nature.
-   **Relevance Grading**: Assesses the quality of retrieved documents to ensure only relevant information is used for generation.
-   **Modular Design**: Built with LangGraph, allowing for a clear and maintainable stateful graph structure.
-   **FastAPI Integration**: Provides a robust and easy-to-use API interface with automatic Swagger/OpenAPI documentation.

## API Endpoints

-   `POST /ask`: The main endpoint that takes a user's question and returns an answer generated by the Adaptive RAG workflow.
-   `POST /ask_test`: A simple test endpoint that echoes the question with a fixed response, useful for basic connectivity checks.
-   `GET /`: A welcome message and a pointer to the API documentation.

## Tech Stack

-   **Framework**: FastAPI
-   **Orchestration**: LangGraph
-   **LLMs & Embeddings**: LangChain (with OpenAI)
-   **Vector Store**: ChromaDB
-   **Web Search**: Tavily (placeholder implementation)
-   **Server**: Uvicorn

## Setup and Installation

1.  **Navigate to the Backend Directory**

    ```bash
    cd backend
    ```

2.  **Create and Activate a Virtual Environment**

    It is highly recommended to use a virtual environment to manage dependencies.

    ```bash
    python3 -m venv rag
    source rag/bin/activate
    ```

3.  **Install Dependencies**

    Install all required packages from `requirements.txt`:

    ```bash
    pip install -r requirements.txt
    ```

4.  **Set Environment Variables**

    This service requires API keys for OpenAI and Tavily. Set them as environment variables. You can add these lines to your shell's configuration file (e.g., `.zshrc` or `.bashrc`) or export them in your current terminal session.

    ```bash
    export OPENAI_API_KEY="your_openai_api_key"
    export TAVILY_API_KEY="your_tavily_api_key"
    ```

    **Note**: The application will fail to start if these environment variables are not set.

## How to Run

1.  **Start the API Server**

    Run the `api.py` script to start the Uvicorn server:

    ```bash
    python api.py
    ```

    The server will be available at `http://0.0.0.0:8000`.

2.  **Access API Documentation**

    Once the server is running, you can access the interactive API documentation (Swagger UI) at:

    [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

3.  **Test the API**

    You can use `curl` or any API client to test the endpoints.

    **Test Endpoint:**
    ```bash
    curl -X POST "http://127.0.0.1:8000/ask_test" -H "Content-Type: application/json" -d '{"question": "Is the API working?"}'
    ```

    **Main RAG Endpoint:**
    ```bash
    curl -X POST "http://127.0.0.1:8000/ask" -H "Content-Type: application/json" -d '{"question": "What are the latest advancements in AI agents?"}'
    ```

## Code Structure

-   `api.py`: Defines the FastAPI application, API endpoints, and server startup logic. It handles incoming requests and calls the RAG workflow.
-   `adaptive_rag.py`: Contains the core logic for the Adaptive RAG workflow. It defines the graph state, nodes (retrieve, grade, generate, web_search), and conditional edges that orchestrate the process.
-   `requirements.txt`: Lists all the Python dependencies for the project.